{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to run SOCNN model on sample toy dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory: 'C:\\\\Users\\\\mbinkowski\\\\cdsol-r-d.cluster\\\\cdsol-r-d.machine_learning_studies\\\\nntimeseries\\\\'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import nnts\n",
    "from nnts.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining sample data frame:\n",
    "- column A enumerates entries, B contains random binomial variables, \n",
    "- columns C and D contain random noise\n",
    "- column E is a sum of last 10 values of B multiplied by D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B         C         D         E\n",
      "0    0  1.0  0.262577  0.916297  0.916297\n",
      "1    1  1.0  0.568105  0.789437  1.705734\n",
      "2    2  0.0  0.272038  0.564149  1.705734\n",
      "3    3  1.0  0.906101  0.455046  2.160780\n",
      "4    4  1.0  0.324807  0.245530  2.406309\n",
      "5    5  1.0  0.296518  0.520783  2.927093\n",
      "6    6  0.0  0.492555  0.256756  2.927093\n",
      "7    7  1.0  0.367418  0.185683  3.112776\n",
      "8    8  1.0  0.045470  0.635562  3.748338\n",
      "9    9  0.0  0.403797  0.548697  3.748338\n",
      "10  10  0.0  0.295046  0.314787  2.832041\n",
      "11  11  1.0  0.016646  0.478048  2.520652\n",
      "12  12  0.0  0.529932  0.126265  2.520652\n",
      "13  13  1.0  0.532256  0.854418  2.920024\n",
      "14  14  0.0  0.597761  0.912888  2.674495\n",
      "15  15  0.0  0.506280  0.390183  2.153711\n",
      "16  16  0.0  0.350338  0.171528  2.153711\n",
      "17  17  0.0  0.377504  0.146421  1.968028\n",
      "18  18  0.0  0.816440  0.496657  1.332466\n",
      "19  19  0.0  0.530889  0.305724  1.332466\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'A': np.arange(1000), \n",
    "                   'B': (np.random.rand(1000)> .5) * 1.0, \n",
    "                   'C': np.random.rand(1000), \n",
    "                   'D': np.random.rand(1000)})\n",
    "df['E'] = df['B'] * df['D'] \n",
    "df['E'] = np.cumsum(df['E'])\n",
    "df.loc[10:, 'E'] -= np.array(df['E'][:-10])\n",
    "print(df.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving data frame to csv. Note that csv format is required by the model to read from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset_file = os.path.join(WDIR, 'data', 'example1.csv')\n",
    "df.to_csv(dataset_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speifying parameters for training. For each of the keyword parameters we define a list of values for grid search.\n",
    "\n",
    "We want to train models that predict column A given B, C and D, and A and E, given B, C and D.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_dict = dict(\n",
    "    # input parameters\n",
    "    input_column_names = [['B', 'C', 'D']],            # input columns \n",
    "    target_column_names = [['E'], ['A', 'E']],         # target columns\n",
    "    diff_column_names = [[]],                          # columns to take first difference of   \n",
    "    verbose = [2],                  # verbosity\n",
    "    train_share = [(.8, .9, 1.)],   # delimeters of the training and validation shares\n",
    "    input_length = [20],            # input length (1 - stateful lstm)\n",
    "    output_length = [1],            # no. of timesteps to predict (only 1 impelemented)\n",
    "    batch_size = [16],              # batch size\n",
    "    objective=['regr'],             # only 'regr' (regression) implemented\n",
    "    #training_parameters\n",
    "    patience = [5],                 # no. of epoch after which learning rate will decrease if no improvement\n",
    "    reduce_nb = [2],                # no. of learning rate reductions\n",
    "    lr = [.01],                     # initial learning rate\n",
    "    clipnorm = [1.0],               # max gradient norm\n",
    "    #model parameters\n",
    "    norm = [10],                    # max norm for fully connected top layer's weights\n",
    "    filters = [8],                  # no. of convolutional filters per layer\n",
    "    act = ['leakyrelu'],            # activation ('linear', 'relu', 'sigmoid', 'tanh', 'leakyrelu')\n",
    "    kernelsize = [[1, 3], 1, 3],    # kernel size (if list of ints passed kernel size changes successively in consecutive layers)\n",
    "    layers_no = [{'sigs': 5, 'offs': 1}],                # no. of layers for significance and offset sub-networks             \n",
    "    architecture = [{'softmax': True, 'lambda': False}], # final activation: lambda=True indicates softplus   \n",
    "    nonnegative = [False],          # if True, apply only nonnegative weights at the top layer\n",
    "    connection_freq = [2],          # vertical connection frequency for ResNet\n",
    "    aux_weight = [0.1],             # auxilllary loss weight\n",
    "    shared_final_weights = [False], # if True, same weights of timesteps for all dimentions are trained\n",
    "    resnet = [False],               # if True, adds vertical connections\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model class import. Other benchmark models such as LSTM, CNN or ResNet can be found in nnts.models module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nnts.models import SOCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the grid seach. Results will be pickled in 'nnts/results' directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 (< limit = 3) computed results for the setting.\n",
      "As yet, for this configuration: success: 0, errors: 0\n",
      "     batch_size: 16\n",
      "      objective: regr\n",
      "     kernelsize: [1, 3]\n",
      "target_column_names: ['E']\n",
      "      reduce_nb: 2\n",
      "       patience: 5\n",
      "   architecture: {'lambda': False, 'softmax': True}\n",
      "connection_freq: 2\n",
      "      layers_no: {'sigs': 5, 'offs': 1}\n",
      "     aux_weight: 0.1\n",
      "    train_share: (0.8, 0.9, 1.0)\n",
      "             lr: 0.01\n",
      "    nonnegative: False\n",
      "input_column_names: ['B', 'C', 'D']\n",
      "           norm: 10\n",
      "            act: leakyrelu\n",
      "       clipnorm: 1.0\n",
      "  output_length: 1\n",
      "         resnet: False\n",
      "        verbose: 2\n",
      "shared_final_weights: False\n",
      "   input_length: 20\n",
      "diff_column_names: []\n",
      "        filters: 8\n",
      "using <class 'nnts.models.SOCNN.SOCNNmodel'> to build the model\n",
      "Total model parameters: 606\n",
      "INFO:tensorflow:Summary name significance1/kernel:0 is illegal; using significance1/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name significance1/kernel:0 is illegal; using significance1/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name significance1/bias:0 is illegal; using significance1/bias_0 instead.\n",
      "INFO:tensorflow:Summary name significance1/bias:0 is illegal; using significance1/bias_0 instead.\n",
      "INFO:tensorflow:Summary name significance1BN/gamma:0 is illegal; using significance1BN/gamma_0 instead.\n",
      "INFO:tensorflow:Summary name significance1BN/gamma:0 is illegal; using significance1BN/gamma_0 instead.\n",
      "INFO:tensorflow:Summary name significance1BN/beta:0 is illegal; using significance1BN/beta_0 instead.\n",
      "INFO:tensorflow:Summary name significance1BN/beta:0 is illegal; using significance1BN/beta_0 instead.\n",
      "INFO:tensorflow:Summary name significance1BN/moving_mean:0 is illegal; using significance1BN/moving_mean_0 instead.\n",
      "INFO:tensorflow:Summary name significance1BN/moving_mean:0 is illegal; using significance1BN/moving_mean_0 instead.\n",
      "INFO:tensorflow:Summary name significance1BN/moving_variance:0 is illegal; using significance1BN/moving_variance_0 instead.\n",
      "INFO:tensorflow:Summary name significance1BN/moving_variance:0 is illegal; using significance1BN/moving_variance_0 instead.\n",
      "INFO:tensorflow:Summary name significance2/kernel:0 is illegal; using significance2/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name significance2/kernel:0 is illegal; using significance2/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name significance2/bias:0 is illegal; using significance2/bias_0 instead.\n",
      "INFO:tensorflow:Summary name significance2/bias:0 is illegal; using significance2/bias_0 instead.\n",
      "INFO:tensorflow:Summary name significance2BN/gamma:0 is illegal; using significance2BN/gamma_0 instead.\n",
      "INFO:tensorflow:Summary name significance2BN/gamma:0 is illegal; using significance2BN/gamma_0 instead.\n",
      "INFO:tensorflow:Summary name significance2BN/beta:0 is illegal; using significance2BN/beta_0 instead.\n",
      "INFO:tensorflow:Summary name significance2BN/beta:0 is illegal; using significance2BN/beta_0 instead.\n",
      "INFO:tensorflow:Summary name significance2BN/moving_mean:0 is illegal; using significance2BN/moving_mean_0 instead.\n",
      "INFO:tensorflow:Summary name significance2BN/moving_mean:0 is illegal; using significance2BN/moving_mean_0 instead.\n",
      "INFO:tensorflow:Summary name significance2BN/moving_variance:0 is illegal; using significance2BN/moving_variance_0 instead.\n",
      "INFO:tensorflow:Summary name significance2BN/moving_variance:0 is illegal; using significance2BN/moving_variance_0 instead.\n",
      "INFO:tensorflow:Summary name significance3/kernel:0 is illegal; using significance3/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name significance3/kernel:0 is illegal; using significance3/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name significance3/bias:0 is illegal; using significance3/bias_0 instead.\n",
      "INFO:tensorflow:Summary name significance3/bias:0 is illegal; using significance3/bias_0 instead.\n",
      "INFO:tensorflow:Summary name significance3BN/gamma:0 is illegal; using significance3BN/gamma_0 instead.\n",
      "INFO:tensorflow:Summary name significance3BN/gamma:0 is illegal; using significance3BN/gamma_0 instead.\n",
      "INFO:tensorflow:Summary name significance3BN/beta:0 is illegal; using significance3BN/beta_0 instead.\n",
      "INFO:tensorflow:Summary name significance3BN/beta:0 is illegal; using significance3BN/beta_0 instead.\n",
      "INFO:tensorflow:Summary name significance3BN/moving_mean:0 is illegal; using significance3BN/moving_mean_0 instead.\n",
      "INFO:tensorflow:Summary name significance3BN/moving_mean:0 is illegal; using significance3BN/moving_mean_0 instead.\n",
      "INFO:tensorflow:Summary name significance3BN/moving_variance:0 is illegal; using significance3BN/moving_variance_0 instead.\n",
      "INFO:tensorflow:Summary name significance3BN/moving_variance:0 is illegal; using significance3BN/moving_variance_0 instead.\n",
      "INFO:tensorflow:Summary name significance4/kernel:0 is illegal; using significance4/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name significance4/kernel:0 is illegal; using significance4/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name significance4/bias:0 is illegal; using significance4/bias_0 instead.\n",
      "INFO:tensorflow:Summary name significance4/bias:0 is illegal; using significance4/bias_0 instead.\n",
      "INFO:tensorflow:Summary name significance4BN/gamma:0 is illegal; using significance4BN/gamma_0 instead.\n",
      "INFO:tensorflow:Summary name significance4BN/gamma:0 is illegal; using significance4BN/gamma_0 instead.\n",
      "INFO:tensorflow:Summary name significance4BN/beta:0 is illegal; using significance4BN/beta_0 instead.\n",
      "INFO:tensorflow:Summary name significance4BN/beta:0 is illegal; using significance4BN/beta_0 instead.\n",
      "INFO:tensorflow:Summary name significance4BN/moving_mean:0 is illegal; using significance4BN/moving_mean_0 instead.\n",
      "INFO:tensorflow:Summary name significance4BN/moving_mean:0 is illegal; using significance4BN/moving_mean_0 instead.\n",
      "INFO:tensorflow:Summary name significance4BN/moving_variance:0 is illegal; using significance4BN/moving_variance_0 instead.\n",
      "INFO:tensorflow:Summary name significance4BN/moving_variance:0 is illegal; using significance4BN/moving_variance_0 instead.\n",
      "INFO:tensorflow:Summary name significance5/kernel:0 is illegal; using significance5/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name significance5/kernel:0 is illegal; using significance5/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name significance5/bias:0 is illegal; using significance5/bias_0 instead.\n",
      "INFO:tensorflow:Summary name significance5/bias:0 is illegal; using significance5/bias_0 instead.\n",
      "INFO:tensorflow:Summary name offset1/kernel:0 is illegal; using offset1/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name offset1/kernel:0 is illegal; using offset1/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name offset1/bias:0 is illegal; using offset1/bias_0 instead.\n",
      "INFO:tensorflow:Summary name offset1/bias:0 is illegal; using offset1/bias_0 instead.\n",
      "INFO:tensorflow:Summary name significance5BN/gamma:0 is illegal; using significance5BN/gamma_0 instead.\n",
      "INFO:tensorflow:Summary name significance5BN/gamma:0 is illegal; using significance5BN/gamma_0 instead.\n",
      "INFO:tensorflow:Summary name significance5BN/beta:0 is illegal; using significance5BN/beta_0 instead.\n",
      "INFO:tensorflow:Summary name significance5BN/beta:0 is illegal; using significance5BN/beta_0 instead.\n",
      "INFO:tensorflow:Summary name significance5BN/moving_mean:0 is illegal; using significance5BN/moving_mean_0 instead.\n",
      "INFO:tensorflow:Summary name significance5BN/moving_mean:0 is illegal; using significance5BN/moving_mean_0 instead.\n",
      "INFO:tensorflow:Summary name significance5BN/moving_variance:0 is illegal; using significance5BN/moving_variance_0 instead.\n",
      "INFO:tensorflow:Summary name significance5BN/moving_variance:0 is illegal; using significance5BN/moving_variance_0 instead.\n",
      "INFO:tensorflow:Summary name offset1BN/gamma:0 is illegal; using offset1BN/gamma_0 instead.\n",
      "INFO:tensorflow:Summary name offset1BN/gamma:0 is illegal; using offset1BN/gamma_0 instead.\n",
      "INFO:tensorflow:Summary name offset1BN/beta:0 is illegal; using offset1BN/beta_0 instead.\n",
      "INFO:tensorflow:Summary name offset1BN/beta:0 is illegal; using offset1BN/beta_0 instead.\n",
      "INFO:tensorflow:Summary name offset1BN/moving_mean:0 is illegal; using offset1BN/moving_mean_0 instead.\n",
      "INFO:tensorflow:Summary name offset1BN/moving_mean:0 is illegal; using offset1BN/moving_mean_0 instead.\n",
      "INFO:tensorflow:Summary name offset1BN/moving_variance:0 is illegal; using offset1BN/moving_variance_0 instead.\n",
      "INFO:tensorflow:Summary name offset1BN/moving_variance:0 is illegal; using offset1BN/moving_variance_0 instead.\n",
      "INFO:tensorflow:Summary name locally_connected1d_1/kernel:0 is illegal; using locally_connected1d_1/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name locally_connected1d_1/kernel:0 is illegal; using locally_connected1d_1/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name locally_connected1d_1/bias:0 is illegal; using locally_connected1d_1/bias_0 instead.\n",
      "INFO:tensorflow:Summary name locally_connected1d_1/bias:0 is illegal; using locally_connected1d_1/bias_0 instead.\n",
      "---current learning rate: 0.01000000\n",
      "Epoch 1/1000\n",
      "\n",
      "---current best val_main_output_loss: 0.99655\n",
      "\n",
      "--- test_loss: 1.201200 - test_main_output_loss: 1.000439 - test_value_output_loss: 2.007608 \n",
      "0s - loss: 1.2389 - main_output_loss: 1.0037 - value_output_loss: 2.3522 - val_loss: 1.1960 - val_main_output_loss: 0.9965 - val_value_output_loss: 1.9942\n",
      "---current learning rate: 0.01000000\n",
      "Epoch 2/1000\n",
      "\n",
      "--- test_loss: 1.186970 - test_main_output_loss: 0.998646 - test_value_output_loss: 1.883231 \n",
      "0s - loss: 1.1914 - main_output_loss: 0.9991 - value_output_loss: 1.9229 - val_loss: 1.1938 - val_main_output_loss: 1.0033 - val_value_output_loss: 1.9045\n",
      "---current learning rate: 0.01000000\n",
      "Epoch 3/1000\n",
      "\n",
      "---current best val_main_output_loss: 0.98659\n",
      "\n",
      "--- test_loss: 1.154241 - test_main_output_loss: 0.995859 - test_value_output_loss: 1.583816 \n",
      "0s - loss: 1.1623 - main_output_loss: 0.9956 - value_output_loss: 1.6664 - val_loss: 1.1514 - val_main_output_loss: 0.9866 - val_value_output_loss: 1.6485\n",
      "---current learning rate: 0.01000000\n",
      "Epoch 4/1000\n",
      "\n",
      "--- test_loss: 1.143406 - test_main_output_loss: 0.996366 - test_value_output_loss: 1.470402 \n",
      "0s - loss: 1.1379 - main_output_loss: 0.9949 - value_output_loss: 1.4295 - val_loss: 1.1532 - val_main_output_loss: 1.0049 - val_value_output_loss: 1.4829\n",
      "---current learning rate: 0.01000000\n",
      "Epoch 5/1000\n",
      "\n",
      "--- test_loss: 1.157019 - test_main_output_loss: 1.013810 - test_value_output_loss: 1.432093 \n",
      "0s - loss: 1.1223 - main_output_loss: 0.9817 - value_output_loss: 1.4063 - val_loss: 1.2515 - val_main_output_loss: 1.1016 - val_value_output_loss: 1.4998\n",
      "---current learning rate: 0.01000000\n",
      "Epoch 6/1000\n",
      "\n",
      "--- test_loss: 1.176063 - test_main_output_loss: 1.037185 - test_value_output_loss: 1.388775 \n",
      "0s - loss: 1.0996 - main_output_loss: 0.9597 - value_output_loss: 1.3991 - val_loss: 1.1465 - val_main_output_loss: 1.0077 - val_value_output_loss: 1.3887\n",
      "---current learning rate: 0.01000000\n",
      "Epoch 7/1000\n",
      "\n",
      "--- test_loss: 1.136413 - test_main_output_loss: 1.000076 - test_value_output_loss: 1.363373 \n",
      "0s - loss: 1.1028 - main_output_loss: 0.9624 - value_output_loss: 1.4039 - val_loss: 1.1558 - val_main_output_loss: 1.0283 - val_value_output_loss: 1.2756\n",
      "---current learning rate: 0.01000000\n",
      "Epoch 8/1000\n",
      "\n",
      "---current best val_main_output_loss: 0.96884\n",
      "\n",
      "--- test_loss: 1.174655 - test_main_output_loss: 1.038149 - test_value_output_loss: 1.365053 \n",
      "0s - loss: 1.0913 - main_output_loss: 0.9512 - value_output_loss: 1.4017 - val_loss: 1.1062 - val_main_output_loss: 0.9688 - val_value_output_loss: 1.3734\n",
      "---current learning rate: 0.01000000\n",
      "Epoch 9/1000\n",
      "\n",
      "--- test_loss: 1.145508 - test_main_output_loss: 1.011198 - test_value_output_loss: 1.343104 \n",
      "0s - loss: 1.0759 - main_output_loss: 0.9387 - value_output_loss: 1.3719 - val_loss: 1.1797 - val_main_output_loss: 1.0437 - val_value_output_loss: 1.3604\n",
      "---current learning rate: 0.01000000\n",
      "Epoch 10/1000\n",
      "\n",
      "---current best val_main_output_loss: 0.94132\n",
      "\n",
      "--- test_loss: 1.164771 - test_main_output_loss: 1.030012 - test_value_output_loss: 1.347588 \n",
      "0s - loss: 1.0822 - main_output_loss: 0.9457 - value_output_loss: 1.3647 - val_loss: 1.0755 - val_main_output_loss: 0.9413 - val_value_output_loss: 1.3419\n",
      "---current learning rate: 0.01000000\n",
      "Epoch 11/1000\n",
      "\n",
      "--- test_loss: 1.195850 - test_main_output_loss: 1.062545 - test_value_output_loss: 1.333059 \n",
      "0s - loss: 1.0613 - main_output_loss: 0.9252 - value_output_loss: 1.3614 - val_loss: 1.2510 - val_main_output_loss: 1.1122 - val_value_output_loss: 1.3879\n",
      "---current learning rate: 0.01000000\n",
      "Epoch 12/1000\n",
      "\n",
      "--- test_loss: 1.175940 - test_main_output_loss: 1.040093 - test_value_output_loss: 1.358477 \n",
      "0s - loss: 1.0719 - main_output_loss: 0.9354 - value_output_loss: 1.3657 - val_loss: 1.0751 - val_main_output_loss: 0.9429 - val_value_output_loss: 1.3225\n",
      "---current learning rate: 0.01000000\n",
      "Epoch 13/1000\n",
      "\n",
      "--- test_loss: 1.208424 - test_main_output_loss: 1.072042 - test_value_output_loss: 1.363816 \n",
      "0s - loss: 1.0564 - main_output_loss: 0.9212 - value_output_loss: 1.3526 - val_loss: 1.2096 - val_main_output_loss: 1.0686 - val_value_output_loss: 1.4102\n",
      "---current learning rate: 0.01000000\n",
      "Epoch 14/1000\n",
      "\n",
      "--- test_loss: 1.190297 - test_main_output_loss: 1.055564 - test_value_output_loss: 1.347333 \n",
      "0s - loss: 1.0630 - main_output_loss: 0.9280 - value_output_loss: 1.3501 - val_loss: 1.0947 - val_main_output_loss: 0.9575 - val_value_output_loss: 1.3721\n",
      "---current learning rate: 0.01000000\n",
      "Epoch 15/1000\n",
      "\n",
      "--- test_loss: 1.181091 - test_main_output_loss: 1.049202 - test_value_output_loss: 1.318893 \n",
      "0s - loss: 1.0546 - main_output_loss: 0.9195 - value_output_loss: 1.3508 - val_loss: 1.2165 - val_main_output_loss: 1.0935 - val_value_output_loss: 1.2300\n",
      "---current learning rate: 0.01000000\n",
      "Epoch 16/1000\n",
      "--- best params restored. \n",
      "\n",
      "--- test_loss: 1.164771 - test_main_output_loss: 1.030012 - test_value_output_loss: 1.347588 \n",
      "1s - loss: 1.0511 - main_output_loss: 0.9165 - value_output_loss: 1.3461 - val_loss: 1.1420 - val_main_output_loss: 0.9923 - val_value_output_loss: 1.4970\n",
      "---current learning rate: 0.00100000\n",
      "Epoch 17/1000\n",
      "\n",
      "--- test_loss: 1.158283 - test_main_output_loss: 1.023390 - test_value_output_loss: 1.348936 \n",
      "0s - loss: 1.0553 - main_output_loss: 0.9205 - value_output_loss: 1.3480 - val_loss: 1.1136 - val_main_output_loss: 0.9782 - val_value_output_loss: 1.3534\n",
      "---current learning rate: 0.00100000\n",
      "Epoch 18/1000\n",
      "\n",
      "--- test_loss: 1.156892 - test_main_output_loss: 1.021598 - test_value_output_loss: 1.352943 \n",
      "0s - loss: 1.0507 - main_output_loss: 0.9114 - value_output_loss: 1.3927 - val_loss: 1.0909 - val_main_output_loss: 0.9567 - val_value_output_loss: 1.3417\n",
      "---current learning rate: 0.00100000\n",
      "Epoch 19/1000\n",
      "\n",
      "--- test_loss: 1.157760 - test_main_output_loss: 1.022454 - test_value_output_loss: 1.353066 \n",
      "0s - loss: 1.0523 - main_output_loss: 0.9168 - value_output_loss: 1.3548 - val_loss: 1.2049 - val_main_output_loss: 1.0606 - val_value_output_loss: 1.4423\n",
      "---current learning rate: 0.00100000\n",
      "Epoch 20/1000\n",
      "\n",
      "--- test_loss: 1.154339 - test_main_output_loss: 1.019079 - test_value_output_loss: 1.352601 \n",
      "0s - loss: 1.0440 - main_output_loss: 0.9072 - value_output_loss: 1.3678 - val_loss: 1.1107 - val_main_output_loss: 0.9803 - val_value_output_loss: 1.3043\n",
      "---current learning rate: 0.00100000\n",
      "Epoch 21/1000\n",
      "\n",
      "--- test_loss: 1.158408 - test_main_output_loss: 1.023121 - test_value_output_loss: 1.352874 \n",
      "0s - loss: 1.0421 - main_output_loss: 0.9054 - value_output_loss: 1.3670 - val_loss: 1.1203 - val_main_output_loss: 0.9826 - val_value_output_loss: 1.3772\n",
      "---current learning rate: 0.00100000\n",
      "Epoch 22/1000\n",
      "--- best params restored. \n",
      "\n",
      "--- test_loss: 1.164771 - test_main_output_loss: 1.030012 - test_value_output_loss: 1.347588 \n",
      "0s - loss: 1.0485 - main_output_loss: 0.9114 - value_output_loss: 1.3710 - val_loss: 1.1034 - val_main_output_loss: 0.9613 - val_value_output_loss: 1.4205\n",
      "---current learning rate: 0.00010000\n",
      "Epoch 23/1000\n",
      "\n",
      "--- test_loss: 1.157360 - test_main_output_loss: 1.022060 - test_value_output_loss: 1.353002 \n",
      "0s - loss: 1.0560 - main_output_loss: 0.9200 - value_output_loss: 1.3603 - val_loss: 1.1247 - val_main_output_loss: 0.9911 - val_value_output_loss: 1.3355\n",
      "---current learning rate: 0.00010000\n",
      "Epoch 24/1000\n",
      "\n",
      "--- test_loss: 1.154812 - test_main_output_loss: 1.019212 - test_value_output_loss: 1.356004 \n",
      "0s - loss: 1.0480 - main_output_loss: 0.9100 - value_output_loss: 1.3795 - val_loss: 1.0977 - val_main_output_loss: 0.9587 - val_value_output_loss: 1.3896\n",
      "---current learning rate: 0.00010000\n",
      "Epoch 25/1000\n",
      "\n",
      "--- test_loss: 1.153688 - test_main_output_loss: 1.017884 - test_value_output_loss: 1.358041 \n",
      "0s - loss: 1.0555 - main_output_loss: 0.9185 - value_output_loss: 1.3700 - val_loss: 1.1578 - val_main_output_loss: 1.0184 - val_value_output_loss: 1.3938\n",
      "---current learning rate: 0.00010000\n",
      "Epoch 26/1000\n",
      "\n",
      "--- test_loss: 1.153003 - test_main_output_loss: 1.017120 - test_value_output_loss: 1.358831 \n",
      "0s - loss: 1.0510 - main_output_loss: 0.9140 - value_output_loss: 1.3699 - val_loss: 1.1623 - val_main_output_loss: 1.0222 - val_value_output_loss: 1.4010\n",
      "---current learning rate: 0.00010000\n",
      "Epoch 27/1000\n",
      "\n",
      "--- test_loss: 1.152597 - test_main_output_loss: 1.016660 - test_value_output_loss: 1.359373 \n",
      "0s - loss: 1.0537 - main_output_loss: 0.9184 - value_output_loss: 1.3529 - val_loss: 1.1528 - val_main_output_loss: 1.0187 - val_value_output_loss: 1.3413\n",
      "---current learning rate: 0.00010000\n",
      "Epoch 28/1000\n",
      "Epoch 27: early stopping\n",
      "\n",
      "--- test_loss: 1.152593 - test_main_output_loss: 1.016619 - test_value_output_loss: 1.359748 \n",
      "0s - loss: 1.0487 - main_output_loss: 0.9117 - value_output_loss: 1.3697 - val_loss: 1.1420 - val_main_output_loss: 1.0038 - val_value_output_loss: 1.3819\n",
      "--- best params restored. \n",
      "setting time 25.39\n",
      "As yet, for this configuration: success: 1, errors: 0\n",
      "     batch_size: 16\n",
      "      objective: regr\n",
      "     kernelsize: [1, 3]\n",
      "target_column_names: ['E']\n",
      "      reduce_nb: 2\n",
      "       patience: 5\n",
      "   architecture: {'lambda': False, 'softmax': True}\n",
      "connection_freq: 2\n",
      "      layers_no: {'sigs': 5, 'offs': 1}\n",
      "     aux_weight: 0.1\n",
      "    train_share: (0.8, 0.9, 1.0)\n",
      "             lr: 0.01\n",
      "    nonnegative: False\n",
      "input_column_names: ['B', 'C', 'D']\n",
      "           norm: 10\n",
      "            act: leakyrelu\n",
      "       clipnorm: 1.0\n",
      "  output_length: 1\n",
      "         resnet: False\n",
      "        verbose: 2\n",
      "shared_final_weights: False\n",
      "   input_length: 20\n",
      "diff_column_names: []\n",
      "        filters: 8\n",
      "using <class 'nnts.models.SOCNN.SOCNNmodel'> to build the model\n",
      "Total model parameters: 606\n",
      "INFO:tensorflow:Summary name significance1_1/kernel:0 is illegal; using significance1_1/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name significance1_1/kernel:0 is illegal; using significance1_1/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name significance1_1/bias:0 is illegal; using significance1_1/bias_0 instead.\n",
      "INFO:tensorflow:Summary name significance1_1/bias:0 is illegal; using significance1_1/bias_0 instead.\n",
      "INFO:tensorflow:Summary name significance1BN_1/gamma:0 is illegal; using significance1BN_1/gamma_0 instead.\n",
      "INFO:tensorflow:Summary name significance1BN_1/gamma:0 is illegal; using significance1BN_1/gamma_0 instead.\n",
      "INFO:tensorflow:Summary name significance1BN_1/beta:0 is illegal; using significance1BN_1/beta_0 instead.\n",
      "INFO:tensorflow:Summary name significance1BN_1/beta:0 is illegal; using significance1BN_1/beta_0 instead.\n",
      "INFO:tensorflow:Summary name significance1BN_1/moving_mean:0 is illegal; using significance1BN_1/moving_mean_0 instead.\n",
      "INFO:tensorflow:Summary name significance1BN_1/moving_mean:0 is illegal; using significance1BN_1/moving_mean_0 instead.\n",
      "INFO:tensorflow:Summary name significance1BN_1/moving_variance:0 is illegal; using significance1BN_1/moving_variance_0 instead.\n",
      "INFO:tensorflow:Summary name significance1BN_1/moving_variance:0 is illegal; using significance1BN_1/moving_variance_0 instead.\n",
      "INFO:tensorflow:Summary name significance2_1/kernel:0 is illegal; using significance2_1/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name significance2_1/kernel:0 is illegal; using significance2_1/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name significance2_1/bias:0 is illegal; using significance2_1/bias_0 instead.\n",
      "INFO:tensorflow:Summary name significance2_1/bias:0 is illegal; using significance2_1/bias_0 instead.\n",
      "INFO:tensorflow:Summary name significance2BN_1/gamma:0 is illegal; using significance2BN_1/gamma_0 instead.\n",
      "INFO:tensorflow:Summary name significance2BN_1/gamma:0 is illegal; using significance2BN_1/gamma_0 instead.\n",
      "INFO:tensorflow:Summary name significance2BN_1/beta:0 is illegal; using significance2BN_1/beta_0 instead.\n",
      "INFO:tensorflow:Summary name significance2BN_1/beta:0 is illegal; using significance2BN_1/beta_0 instead.\n",
      "INFO:tensorflow:Summary name significance2BN_1/moving_mean:0 is illegal; using significance2BN_1/moving_mean_0 instead.\n",
      "INFO:tensorflow:Summary name significance2BN_1/moving_mean:0 is illegal; using significance2BN_1/moving_mean_0 instead.\n",
      "INFO:tensorflow:Summary name significance2BN_1/moving_variance:0 is illegal; using significance2BN_1/moving_variance_0 instead.\n",
      "INFO:tensorflow:Summary name significance2BN_1/moving_variance:0 is illegal; using significance2BN_1/moving_variance_0 instead.\n",
      "INFO:tensorflow:Summary name significance3_1/kernel:0 is illegal; using significance3_1/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name significance3_1/kernel:0 is illegal; using significance3_1/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name significance3_1/bias:0 is illegal; using significance3_1/bias_0 instead.\n",
      "INFO:tensorflow:Summary name significance3_1/bias:0 is illegal; using significance3_1/bias_0 instead.\n",
      "INFO:tensorflow:Summary name significance3BN_1/gamma:0 is illegal; using significance3BN_1/gamma_0 instead.\n",
      "INFO:tensorflow:Summary name significance3BN_1/gamma:0 is illegal; using significance3BN_1/gamma_0 instead.\n",
      "INFO:tensorflow:Summary name significance3BN_1/beta:0 is illegal; using significance3BN_1/beta_0 instead.\n",
      "INFO:tensorflow:Summary name significance3BN_1/beta:0 is illegal; using significance3BN_1/beta_0 instead.\n",
      "INFO:tensorflow:Summary name significance3BN_1/moving_mean:0 is illegal; using significance3BN_1/moving_mean_0 instead.\n",
      "INFO:tensorflow:Summary name significance3BN_1/moving_mean:0 is illegal; using significance3BN_1/moving_mean_0 instead.\n",
      "INFO:tensorflow:Summary name significance3BN_1/moving_variance:0 is illegal; using significance3BN_1/moving_variance_0 instead.\n",
      "INFO:tensorflow:Summary name significance3BN_1/moving_variance:0 is illegal; using significance3BN_1/moving_variance_0 instead.\n",
      "INFO:tensorflow:Summary name significance4_1/kernel:0 is illegal; using significance4_1/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name significance4_1/kernel:0 is illegal; using significance4_1/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name significance4_1/bias:0 is illegal; using significance4_1/bias_0 instead.\n",
      "INFO:tensorflow:Summary name significance4_1/bias:0 is illegal; using significance4_1/bias_0 instead.\n",
      "INFO:tensorflow:Summary name significance4BN_1/gamma:0 is illegal; using significance4BN_1/gamma_0 instead.\n",
      "INFO:tensorflow:Summary name significance4BN_1/gamma:0 is illegal; using significance4BN_1/gamma_0 instead.\n",
      "INFO:tensorflow:Summary name significance4BN_1/beta:0 is illegal; using significance4BN_1/beta_0 instead.\n",
      "INFO:tensorflow:Summary name significance4BN_1/beta:0 is illegal; using significance4BN_1/beta_0 instead.\n",
      "INFO:tensorflow:Summary name significance4BN_1/moving_mean:0 is illegal; using significance4BN_1/moving_mean_0 instead.\n",
      "INFO:tensorflow:Summary name significance4BN_1/moving_mean:0 is illegal; using significance4BN_1/moving_mean_0 instead.\n",
      "INFO:tensorflow:Summary name significance4BN_1/moving_variance:0 is illegal; using significance4BN_1/moving_variance_0 instead.\n",
      "INFO:tensorflow:Summary name significance4BN_1/moving_variance:0 is illegal; using significance4BN_1/moving_variance_0 instead.\n",
      "INFO:tensorflow:Summary name significance5_1/kernel:0 is illegal; using significance5_1/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name significance5_1/kernel:0 is illegal; using significance5_1/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name significance5_1/bias:0 is illegal; using significance5_1/bias_0 instead.\n",
      "INFO:tensorflow:Summary name significance5_1/bias:0 is illegal; using significance5_1/bias_0 instead.\n",
      "INFO:tensorflow:Summary name offset1_1/kernel:0 is illegal; using offset1_1/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name offset1_1/kernel:0 is illegal; using offset1_1/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name offset1_1/bias:0 is illegal; using offset1_1/bias_0 instead.\n",
      "INFO:tensorflow:Summary name offset1_1/bias:0 is illegal; using offset1_1/bias_0 instead.\n",
      "INFO:tensorflow:Summary name significance5BN_1/gamma:0 is illegal; using significance5BN_1/gamma_0 instead.\n",
      "INFO:tensorflow:Summary name significance5BN_1/gamma:0 is illegal; using significance5BN_1/gamma_0 instead.\n",
      "INFO:tensorflow:Summary name significance5BN_1/beta:0 is illegal; using significance5BN_1/beta_0 instead.\n",
      "INFO:tensorflow:Summary name significance5BN_1/beta:0 is illegal; using significance5BN_1/beta_0 instead.\n",
      "INFO:tensorflow:Summary name significance5BN_1/moving_mean:0 is illegal; using significance5BN_1/moving_mean_0 instead.\n",
      "INFO:tensorflow:Summary name significance5BN_1/moving_mean:0 is illegal; using significance5BN_1/moving_mean_0 instead.\n",
      "INFO:tensorflow:Summary name significance5BN_1/moving_variance:0 is illegal; using significance5BN_1/moving_variance_0 instead.\n",
      "INFO:tensorflow:Summary name significance5BN_1/moving_variance:0 is illegal; using significance5BN_1/moving_variance_0 instead.\n",
      "INFO:tensorflow:Summary name offset1BN_1/gamma:0 is illegal; using offset1BN_1/gamma_0 instead.\n",
      "INFO:tensorflow:Summary name offset1BN_1/gamma:0 is illegal; using offset1BN_1/gamma_0 instead.\n",
      "INFO:tensorflow:Summary name offset1BN_1/beta:0 is illegal; using offset1BN_1/beta_0 instead.\n",
      "INFO:tensorflow:Summary name offset1BN_1/beta:0 is illegal; using offset1BN_1/beta_0 instead.\n",
      "INFO:tensorflow:Summary name offset1BN_1/moving_mean:0 is illegal; using offset1BN_1/moving_mean_0 instead.\n",
      "INFO:tensorflow:Summary name offset1BN_1/moving_mean:0 is illegal; using offset1BN_1/moving_mean_0 instead.\n",
      "INFO:tensorflow:Summary name offset1BN_1/moving_variance:0 is illegal; using offset1BN_1/moving_variance_0 instead.\n",
      "INFO:tensorflow:Summary name offset1BN_1/moving_variance:0 is illegal; using offset1BN_1/moving_variance_0 instead.\n",
      "INFO:tensorflow:Summary name locally_connected1d_2/kernel:0 is illegal; using locally_connected1d_2/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name locally_connected1d_2/kernel:0 is illegal; using locally_connected1d_2/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name locally_connected1d_2/bias:0 is illegal; using locally_connected1d_2/bias_0 instead.\n",
      "INFO:tensorflow:Summary name locally_connected1d_2/bias:0 is illegal; using locally_connected1d_2/bias_0 instead.\n",
      "---current learning rate: 0.01000000\n",
      "Epoch 1/1000\n",
      "\n",
      "---current best val_main_output_loss: 0.99735\n",
      "\n",
      "--- test_loss: 1.142028 - test_main_output_loss: 0.996368 - test_value_output_loss: 1.456595 \n",
      "0s - loss: 1.1520 - main_output_loss: 1.0016 - value_output_loss: 1.5043 - val_loss: 1.1479 - val_main_output_loss: 0.9973 - val_value_output_loss: 1.5060\n",
      "---current learning rate: 0.01000000\n",
      "Epoch 2/1000\n",
      "\n",
      "--- test_loss: 1.135214 - test_main_output_loss: 0.993725 - test_value_output_loss: 1.414893 \n",
      "0s - loss: 1.1354 - main_output_loss: 0.9949 - value_output_loss: 1.4051 - val_loss: 1.1496 - val_main_output_loss: 1.0108 - val_value_output_loss: 1.3884\n",
      "---current learning rate: 0.01000000\n",
      "Epoch 3/1000\n",
      "\n",
      "---current best val_main_output_loss: 0.99204\n",
      "\n",
      "--- test_loss: 1.131461 - test_main_output_loss: 0.993643 - test_value_output_loss: 1.378189 \n",
      "0s - loss: 1.1319 - main_output_loss: 0.9934 - value_output_loss: 1.3849 - val_loss: 1.1380 - val_main_output_loss: 0.9920 - val_value_output_loss: 1.4597\n",
      "---current learning rate: 0.01000000\n",
      "Epoch 4/1000\n",
      "\n",
      "--- test_loss: 1.128286 - test_main_output_loss: 0.992066 - test_value_output_loss: 1.362203 \n",
      "0s - loss: 1.1206 - main_output_loss: 0.9846 - value_output_loss: 1.3603 - val_loss: 1.1325 - val_main_output_loss: 0.9942 - val_value_output_loss: 1.3831\n",
      "---current learning rate: 0.01000000\n",
      "Epoch 5/1000\n",
      "\n",
      "--- test_loss: 1.120247 - test_main_output_loss: 0.987721 - test_value_output_loss: 1.325265 \n",
      "0s - loss: 1.1141 - main_output_loss: 0.9782 - value_output_loss: 1.3592 - val_loss: 1.1382 - val_main_output_loss: 1.0116 - val_value_output_loss: 1.2664\n",
      "---current learning rate: 0.01000000\n",
      "Epoch 6/1000\n",
      "\n",
      "--- test_loss: 1.110041 - test_main_output_loss: 0.978387 - test_value_output_loss: 1.316537 \n",
      "0s - loss: 1.1043 - main_output_loss: 0.9724 - value_output_loss: 1.3187 - val_loss: 1.1341 - val_main_output_loss: 0.9932 - val_value_output_loss: 1.4094\n",
      "---current learning rate: 0.01000000\n",
      "Epoch 7/1000\n",
      "\n",
      "--- test_loss: 1.177537 - test_main_output_loss: 1.047358 - test_value_output_loss: 1.301787 \n",
      "0s - loss: 1.1069 - main_output_loss: 0.9758 - value_output_loss: 1.3104 - val_loss: 1.1906 - val_main_output_loss: 1.0666 - val_value_output_loss: 1.2398\n",
      "---current learning rate: 0.01000000\n",
      "Epoch 8/1000\n",
      "\n",
      "--- test_loss: 1.150480 - test_main_output_loss: 1.017651 - test_value_output_loss: 1.328282 \n",
      "0s - loss: 1.0910 - main_output_loss: 0.9585 - value_output_loss: 1.3250 - val_loss: 1.1717 - val_main_output_loss: 1.0362 - val_value_output_loss: 1.3550\n",
      "---current learning rate: 0.01000000\n",
      "Epoch 9/1000\n",
      "--- best params restored. \n",
      "\n",
      "--- test_loss: 1.131461 - test_main_output_loss: 0.993643 - test_value_output_loss: 1.378189 \n",
      "3s - loss: 1.0938 - main_output_loss: 0.9646 - value_output_loss: 1.2915 - val_loss: 1.1871 - val_main_output_loss: 1.0618 - val_value_output_loss: 1.2531\n",
      "---current learning rate: 0.00100000\n",
      "Epoch 10/1000\n",
      "\n",
      "---current best val_main_output_loss: 0.98552\n",
      "\n",
      "--- test_loss: 1.131929 - test_main_output_loss: 0.994915 - test_value_output_loss: 1.370137 \n",
      "0s - loss: 1.1103 - main_output_loss: 0.9728 - value_output_loss: 1.3753 - val_loss: 1.1330 - val_main_output_loss: 0.9855 - val_value_output_loss: 1.4746\n",
      "---current learning rate: 0.00100000\n",
      "Epoch 11/1000\n",
      "\n",
      "--- test_loss: 1.132663 - test_main_output_loss: 0.996130 - test_value_output_loss: 1.365336 \n",
      "0s - loss: 1.1084 - main_output_loss: 0.9717 - value_output_loss: 1.3672 - val_loss: 1.1432 - val_main_output_loss: 1.0139 - val_value_output_loss: 1.2931\n",
      "---current learning rate: 0.00100000\n",
      "Epoch 12/1000\n",
      "\n",
      "--- test_loss: 1.134868 - test_main_output_loss: 0.998656 - test_value_output_loss: 1.362116 \n",
      "0s - loss: 1.1023 - main_output_loss: 0.9660 - value_output_loss: 1.3627 - val_loss: 1.1371 - val_main_output_loss: 0.9927 - val_value_output_loss: 1.4440\n",
      "---current learning rate: 0.00100000\n",
      "Epoch 13/1000\n",
      "\n",
      "--- test_loss: 1.133881 - test_main_output_loss: 0.997949 - test_value_output_loss: 1.359320 \n",
      "0s - loss: 1.1046 - main_output_loss: 0.9672 - value_output_loss: 1.3737 - val_loss: 1.1401 - val_main_output_loss: 1.0108 - val_value_output_loss: 1.2921\n",
      "---current learning rate: 0.00100000\n",
      "Epoch 14/1000\n",
      "\n",
      "---current best val_main_output_loss: 0.97894\n",
      "\n",
      "--- test_loss: 1.135974 - test_main_output_loss: 1.000244 - test_value_output_loss: 1.357297 \n",
      "0s - loss: 1.0989 - main_output_loss: 0.9625 - value_output_loss: 1.3637 - val_loss: 1.1252 - val_main_output_loss: 0.9789 - val_value_output_loss: 1.4630\n",
      "---current learning rate: 0.00100000\n",
      "Epoch 15/1000\n",
      "\n",
      "--- test_loss: 1.138012 - test_main_output_loss: 1.002402 - test_value_output_loss: 1.356109 \n",
      "0s - loss: 1.0959 - main_output_loss: 0.9595 - value_output_loss: 1.3647 - val_loss: 1.1410 - val_main_output_loss: 1.0015 - val_value_output_loss: 1.3950\n",
      "---current learning rate: 0.00100000\n",
      "Epoch 16/1000\n",
      "\n",
      "--- test_loss: 1.137709 - test_main_output_loss: 1.002187 - test_value_output_loss: 1.355217 \n",
      "0s - loss: 1.0948 - main_output_loss: 0.9590 - value_output_loss: 1.3579 - val_loss: 1.1493 - val_main_output_loss: 1.0217 - val_value_output_loss: 1.2762\n",
      "---current learning rate: 0.00100000\n",
      "Epoch 17/1000\n",
      "\n",
      "--- test_loss: 1.138822 - test_main_output_loss: 1.003381 - test_value_output_loss: 1.354410 \n",
      "0s - loss: 1.0926 - main_output_loss: 0.9569 - value_output_loss: 1.3564 - val_loss: 1.1363 - val_main_output_loss: 1.0032 - val_value_output_loss: 1.3308\n",
      "---current learning rate: 0.00100000\n",
      "Epoch 18/1000\n",
      "\n",
      "--- test_loss: 1.137533 - test_main_output_loss: 1.002154 - test_value_output_loss: 1.353787 \n",
      "0s - loss: 1.0934 - main_output_loss: 0.9562 - value_output_loss: 1.3719 - val_loss: 1.1380 - val_main_output_loss: 0.9977 - val_value_output_loss: 1.4037\n",
      "---current learning rate: 0.00100000\n",
      "Epoch 19/1000\n",
      "\n",
      "--- test_loss: 1.138425 - test_main_output_loss: 1.003141 - test_value_output_loss: 1.352842 \n",
      "0s - loss: 1.0904 - main_output_loss: 0.9534 - value_output_loss: 1.3697 - val_loss: 1.1508 - val_main_output_loss: 1.0194 - val_value_output_loss: 1.3134\n",
      "---current learning rate: 0.00100000\n",
      "Epoch 20/1000\n",
      "--- best params restored. \n",
      "\n",
      "--- test_loss: 1.135974 - test_main_output_loss: 1.000244 - test_value_output_loss: 1.357297 \n",
      "0s - loss: 1.0812 - main_output_loss: 0.9476 - value_output_loss: 1.3365 - val_loss: 1.1519 - val_main_output_loss: 1.0154 - val_value_output_loss: 1.3653\n",
      "---current learning rate: 0.00010000\n",
      "Epoch 21/1000\n",
      "\n",
      "--- test_loss: 1.137390 - test_main_output_loss: 1.001680 - test_value_output_loss: 1.357098 \n",
      "0s - loss: 1.0924 - main_output_loss: 0.9551 - value_output_loss: 1.3730 - val_loss: 1.1300 - val_main_output_loss: 0.9899 - val_value_output_loss: 1.4014\n",
      "---current learning rate: 0.00010000\n",
      "Epoch 22/1000\n",
      "\n",
      "--- test_loss: 1.138399 - test_main_output_loss: 1.002687 - test_value_output_loss: 1.357111 \n",
      "0s - loss: 1.1006 - main_output_loss: 0.9649 - value_output_loss: 1.3572 - val_loss: 1.1318 - val_main_output_loss: 0.9942 - val_value_output_loss: 1.3754\n",
      "---current learning rate: 0.00010000\n",
      "Epoch 23/1000\n",
      "\n",
      "--- test_loss: 1.138709 - test_main_output_loss: 1.003039 - test_value_output_loss: 1.356701 \n",
      "0s - loss: 1.0977 - main_output_loss: 0.9623 - value_output_loss: 1.3541 - val_loss: 1.1393 - val_main_output_loss: 0.9945 - val_value_output_loss: 1.4476\n",
      "---current learning rate: 0.00010000\n",
      "Epoch 24/1000\n",
      "\n",
      "--- test_loss: 1.139118 - test_main_output_loss: 1.003426 - test_value_output_loss: 1.356923 \n",
      "0s - loss: 1.0938 - main_output_loss: 0.9564 - value_output_loss: 1.3738 - val_loss: 1.1368 - val_main_output_loss: 1.0043 - val_value_output_loss: 1.3254\n",
      "---current learning rate: 0.00010000\n",
      "Epoch 25/1000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-1a9615c4c860>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mrunner\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnnts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModelRunner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdataset_file\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrunner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSOCNN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSOCNNmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Users\\mbinkowski\\cdsol-r-d.cluster\\cdsol-r-d.machine_learning_studies\\nntimeseries\\nnts\\utils.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, model_class, trials, log, read_file, limit, irrelevant)\u001b[0m\n\u001b[1;32m    128\u001b[0m                     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mWDIR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'tensorboard'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[1;31m#                    history, nn, reducer = model.run()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                     \u001b[0mmodel_results\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[1;31m#                    self.reducer = reducer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\mbinkowski\\cdsol-r-d.cluster\\cdsol-r-d.machine_learning_studies\\nntimeseries\\nnts\\utils.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'valid'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m             \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_size\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m             \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m         )\n\u001b[1;32m    289\u001b[0m         \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Anaconda3\\envs\\tf35\\lib\\site-packages\\keras-2.0.2-py3.5.egg\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Anaconda3\\envs\\tf35\\lib\\site-packages\\keras-2.0.2-py3.5.egg\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_q_size, workers, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1881\u001b[0m                         \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1883\u001b[0;31m                     \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1884\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1885\u001b[0m                     \u001b[1;31m# Construct epoch logs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Anaconda3\\envs\\tf35\\lib\\site-packages\\keras-2.0.2-py3.5.egg\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delta_ts_batch_end\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0mdelta_t_median\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delta_ts_batch_end\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         if (self._delta_t_batch > 0. and\n\u001b[1;32m    115\u001b[0m            (delta_t_median > 0.95 * self._delta_t_batch and delta_t_median > 0.1)):\n",
      "\u001b[0;32mC:\\Anaconda3\\envs\\tf35\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36mmedian\u001b[0;34m(a, axis, out, overwrite_input, keepdims)\u001b[0m\n\u001b[1;32m   3942\u001b[0m     \"\"\"\n\u001b[1;32m   3943\u001b[0m     r, k = _ureduce(a, func=_median, axis=axis, out=out,\n\u001b[0;32m-> 3944\u001b[0;31m                     overwrite_input=overwrite_input)\n\u001b[0m\u001b[1;32m   3945\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3946\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Anaconda3\\envs\\tf35\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36m_ureduce\u001b[0;34m(a, func, **kwargs)\u001b[0m\n\u001b[1;32m   3856\u001b[0m         \u001b[0mkeepdim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3858\u001b[0;31m     \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3859\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3860\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Anaconda3\\envs\\tf35\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36m_median\u001b[0;34m(a, axis, out, overwrite_input)\u001b[0m\n\u001b[1;32m   3975\u001b[0m             \u001b[0mpart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3976\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3977\u001b[0;31m         \u001b[0mpart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpartition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3978\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3979\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Anaconda3\\envs\\tf35\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mpartition\u001b[0;34m(a, kth, axis, kind, order)\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m         \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"K\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m     \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    640\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "save_file = os.path.join(WDIR, 'results', 'example_model.pkl')\n",
    "runner = nnts.utils.ModelRunner(param_dict, [dataset_file], save_file)\n",
    "\n",
    "results = runner.run(SOCNN.SOCNNmodel, log=False, limit=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results are stored in a list of dictionaries. Each dictionary stores parameters and results (loss function values troughout consecutive epochs) that correspond to each single model fitted during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## results[0] ##########\n",
      "               batch_size: 16\n",
      "    val_value_output_loss: [1.5225844144821168, 1.4680827140808106, 1.4728038549423217, 1.4350318670272828, ...\n",
      "         main_output_loss: [0.99950292582313216, 1.0015199854969978, 0.99857743084430695, 0.998141956826051 ...\n",
      "               layer_size: nan\n",
      "                 val_loss: [1.1492438793182373, 1.1463390588760376, 1.1410159826278687, 1.1299276351928711, ...\n",
      "               epoch_time: [20.58132839202881, 21.08583354949951, 21.58590078353882, 22.119659900665283, 22 ...\n",
      "                test_loss: [1.1629176139831543, 1.1550909042358399, 1.147585678100586, 1.1455643892288208,  ...\n",
      "                  verbose: 1\n",
      "            training_time: 37.48593258857727\n",
      "                 patience: 5\n",
      "          connection_freq: 2.0\n",
      "               aux_weight: 0.1\n",
      "              train_share: (0.8, 0.9, 1.0)\n",
      "              nonnegative: False\n",
      "                 datetime: 2017-09-19T18:52:35.811768\n",
      "                     date: 2017-09-19\n",
      "              target_cols: nan\n",
      "            output_length: 1\n",
      "        value_output_loss: [1.6331174795826275, 1.3962897571424644, 1.3818610620995362, 1.3650727632145088, ...\n",
      "               kernelsize: [1, 3]\n",
      "                reduce_nb: 2\n",
      "   test_value_output_loss: [1.6100340127944945, 1.5409381151199342, 1.4970032930374146, 1.4633044004440308, ...\n",
      "                     hdf5: C:\\Users\\mbinkowski\\cdsol-r-d.cluster\\cdsol-r-d.machine_learning_studies\\nntimes ...\n",
      "                  filters: 8.0\n",
      "                objective: regr\n",
      "    test_main_output_loss: [1.0019142150878906, 1.0009971022605897, 0.99788534641265869, 0.9992339611053466 ...\n",
      "                     loss: [1.1628146693110466, 1.1411489645640056, 1.136763537923495, 1.1346492320299149,  ...\n",
      "             total_params: 606.0\n",
      "      target_column_names: ['A']\n",
      "                layers_no: {'sigs': 5, 'offs': 1}\n",
      "             architecture: {'lambda': False, 'softmax': True}\n",
      "                  dropout: nan\n",
      "                       lr: 0.01\n",
      "       input_column_names: ['B', 'C', 'D']\n",
      "                     norm: 10\n",
      "                     data: C:\\Users\\mbinkowski\\cdsol-r-d.cluster\\cdsol-r-d.machine_learning_studies\\nntimes ...\n",
      "                      act: leakyrelu\n",
      "                 clipnorm: 1.0\n",
      "                    diffs: nan\n",
      "                   resnet: False\n",
      "     val_main_output_loss: [0.99698543548583984, 0.99953079223632813, 0.99373559951782231, 0.98642444610595 ...\n",
      "     shared_final_weights: False\n",
      "             input_length: 20\n",
      "        diff_column_names: []\n",
      "                       dt: 2017-09-19 18:52:35.811768\n",
      "\n",
      "\n",
      "\n",
      "########## results[1] ##########\n",
      "               batch_size: 128\n",
      "    val_value_output_loss: nan\n",
      "         main_output_loss: nan\n",
      "               layer_size: 64.0\n",
      "                 val_loss: [1.7041687965393066, 1.6422009468078613, 1.7041687965393066, 1.6112169027328491, ...\n",
      "               epoch_time: [25.679571866989136, 25.86709427833557, 26.117124557495117, 26.414066553115845,  ...\n",
      "                test_loss: [2.0140087604522705, 2.0140087604522705, 2.0140087604522705, 2.0140087604522705, ...\n",
      "                  verbose: 1\n",
      "            training_time: 49.78043246269226\n",
      "                 patience: 10\n",
      "          connection_freq: nan\n",
      "               aux_weight: nan\n",
      "              train_share: (0.7, 0.8, 1.0)\n",
      "              nonnegative: nan\n",
      "                 datetime: 2017-09-19T19:41:06.905298\n",
      "                     date: 2017-09-19\n",
      "              target_cols: default\n",
      "            output_length: 1\n",
      "        value_output_loss: nan\n",
      "               kernelsize: nan\n",
      "                reduce_nb: 2\n",
      "   test_value_output_loss: nan\n",
      "                     hdf5: C:\\Users\\mbinkowski\\cdsol-r-d.cluster\\cdsol-r-d.machine_learning_studies\\nntimes ...\n",
      "                  filters: nan\n",
      "                objective: regr\n",
      "    test_main_output_loss: nan\n",
      "                     loss: [1.9892215967178344, 1.9458439350128174, 2.0449927330017088, 1.939647126197815,  ...\n",
      "             total_params: 4.0\n",
      "      target_column_names: ['E']\n",
      "                layers_no: 1\n",
      "             architecture: nan\n",
      "                  dropout: 0.0\n",
      "                       lr: 1e-05\n",
      "       input_column_names: ['B', 'C', 'D']\n",
      "                     norm: 1\n",
      "                     data: C:\\Users\\mbinkowski\\cdsol-r-d.cluster\\cdsol-r-d.machine_learning_studies\\nntimes ...\n",
      "                      act: leakyrelu\n",
      "                 clipnorm: 0.001\n",
      "                    diffs: False\n",
      "                   resnet: nan\n",
      "     val_main_output_loss: nan\n",
      "     shared_final_weights: nan\n",
      "             input_length: 1\n",
      "        diff_column_names: []\n",
      "                       dt: 2017-09-19 19:41:06.905298\n",
      "\n",
      "\n",
      "\n",
      "########## results[2] ##########\n",
      "               batch_size: 16\n",
      "    val_value_output_loss: [2.1170169830322267, 1.9795753955841064, 1.9699110984802246, 1.9656433105468749, ...\n",
      "         main_output_loss: [1.0050846921900909, 0.99661840250094735, 0.99060041209061944, 0.974974591284990 ...\n",
      "               layer_size: nan\n",
      "                 val_loss: [1.2146104574203491, 1.2042478799819947, 1.2085369586944581, 1.2300858736038207, ...\n",
      "               epoch_time: [9.778083324432373, 10.26197099685669, 10.755284309387207, 11.245591640472412, 1 ...\n",
      "                test_loss: [1.2240301132202149, 1.2042144298553468, 1.2009509563446046, 1.2449235200881958, ...\n",
      "                  verbose: 1\n",
      "            training_time: 26.79829692840576\n",
      "                 patience: 5\n",
      "          connection_freq: 2.0\n",
      "               aux_weight: 0.1\n",
      "              train_share: (0.8, 0.9, 1.0)\n",
      "              nonnegative: False\n",
      "                 datetime: 2017-09-26T17:57:44.220396\n",
      "                     date: 2017-09-26\n",
      "              target_cols: nan\n",
      "            output_length: 1\n",
      "        value_output_loss: [2.5264737953742347, 2.0491566161314645, 1.9946068873008092, 1.9858877261479695, ...\n",
      "               kernelsize: [1, 3]\n",
      "                reduce_nb: 2\n",
      "   test_value_output_loss: [2.2345387935638428, 2.0432312488555908, 2.0281495332717894, 2.0161866664886476, ...\n",
      "                     hdf5: C:\\Users\\mbinkowski\\cdsol-r-d.cluster\\cdsol-r-d.machine_learning_studies\\nntimes ...\n",
      "                  filters: 8.0\n",
      "                objective: regr\n",
      "    test_main_output_loss: [1.0005762338638307, 0.99989131689071653, 0.99813600778579714, 1.043304848670959 ...\n",
      "                     loss: [1.2577320709824562, 1.2015340675910313, 1.1900610973437626, 1.1735633611679077, ...\n",
      "             total_params: 606.0\n",
      "      target_column_names: ['E']\n",
      "                layers_no: {'sigs': 5, 'offs': 1}\n",
      "             architecture: {'lambda': False, 'softmax': True}\n",
      "                  dropout: nan\n",
      "                       lr: 0.01\n",
      "       input_column_names: ['B', 'C', 'D']\n",
      "                     norm: 10\n",
      "                     data: C:\\Users\\mbinkowski\\cdsol-r-d.cluster\\cdsol-r-d.machine_learning_studies\\nntimes ...\n",
      "                      act: leakyrelu\n",
      "                 clipnorm: 1.0\n",
      "                    diffs: nan\n",
      "                   resnet: False\n",
      "     val_main_output_loss: [1.0029087662696838, 1.0062903404235839, 1.0115458488464355, 1.033521544933319,  ...\n",
      "     shared_final_weights: False\n",
      "             input_length: 20\n",
      "        diff_column_names: []\n",
      "                       dt: 2017-09-26 17:57:44.220396\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, r in enumerate(results[:3]):\n",
    "    print('########## results[%d] ##########' % i)\n",
    "    for k, v in r.items():\n",
    "        print(str(k).rjust(25) + ': ' + str(v)[:80] + ' ...' * (len(str(v)) > 80 ))\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tf35]",
   "language": "python",
   "name": "conda-env-tf35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
